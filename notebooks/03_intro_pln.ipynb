{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 03 – Modelos BERT, GPT, T5 + Pipeline com Hugging Face\n",
    "\n",
    "Notebook com **duas formas** de utilizar modelos de linguagem:\n",
    "\n",
    "1. **Modo básico**: usando `transformers` diretamente com `AutoTokenizer` e `AutoModel`\n",
    "2. **Modo simplificado**: usando `pipeline` com modelos pré-treinados e `datasets`\n",
    "\n",
    "Vamos abordar:\n",
    "- BERT (Masked Language Modeling)\n",
    "- GPT (Causal Language Modeling)\n",
    "- T5 (Text-to-Text)\n",
    "- Zero-shot Classification\n",
    "- Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação necessária (caso ainda não tenha)\n",
    "# !pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT - Preenchendo Máscaras (Masked Language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "frase = \"The student went to the [MASK] to study.\"\n",
    "tokens = tokenizer(frase, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "predicted_token_id = outputs.logits[0, tokens['input_ids'][0].tolist().index(tokenizer.mask_token_id)].argmax().item()\n",
    "predicted_word = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "print(\"Frase original:\", frase)\n",
    "print(\"Palavra predita:\", predicted_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT - Geração de Texto (Causal Language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "entrada = tokenizer(\"Once upon a time\", return_tensors=\"pt\")\n",
    "saida = model.generate(**entrada, max_length=20)\n",
    "\n",
    "print(tokenizer.decode(saida[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 - Tradução de Tarefa para Texto (Text-to-Text Transfer Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "entrada = tokenizer(\"translate English to Portuguese: I love natural language processing\", return_tensors=\"pt\")\n",
    "saida = model.generate(**entrada)\n",
    "\n",
    "print(tokenizer.decode(saida[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot Classification com Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classificador = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "resultado = classificador(\n",
    "    \"Esse curso ensina como treinar modelos de linguagem\",\n",
    "    candidate_labels=[\"esporte\", \"tecnologia\", \"culinária\"]\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER (Reconhecimento de Entidades Nomeadas) com Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "texto = \"Barack Obama foi presidente dos Estados Unidos.\"\n",
    "entidades = ner(texto)\n",
    "print(entidades)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
